{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3895159",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa063090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Kwaai/IMDB_Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67df7a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "822a8345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total text: 50000\n",
      "Number of unique text: 49582\n",
      "Is there any duplicate text? : True\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# combine train + test a full dataset\n",
    "full_dataset = concatenate_datasets([ds['train'], ds['test']])  # 50,000\n",
    "\n",
    "# count all\n",
    "total = len(full_dataset)\n",
    "\n",
    "# count unique text\n",
    "unique = len(set(full_dataset['text']))\n",
    "\n",
    "print(f\"Number of total text: {total}\")\n",
    "print(f\"Number of unique text: {unique}\")\n",
    "print(f\"Is there any duplicate text? : {total != unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea5d238d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 34707\n",
      "Validation size: 9916\n",
      "Test size: 4959\n"
     ]
    }
   ],
   "source": [
    "df = full_dataset.to_pandas()\n",
    "\n",
    "# unique\n",
    "df_unique = df.drop_duplicates(subset=\"text\")\n",
    "\n",
    "# transfer to dataset\n",
    "full_dataset = Dataset.from_pandas(df_unique)\n",
    "\n",
    "# split dataset\n",
    "split1 = full_dataset.train_test_split(test_size=0.3, seed=42)\n",
    "train = split1['train']\n",
    "temp = split1['test']\n",
    "\n",
    "split2 = temp.train_test_split(test_size=1/3, seed=42)\n",
    "validation = split2['train']\n",
    "test = split2['test']\n",
    "\n",
    "\n",
    "dataset = {\n",
    "    \"train\": train,\n",
    "    \"validation\": validation,\n",
    "    \"test\": test\n",
    "}\n",
    "\n",
    "print(\"Train size:\", len(dataset[\"train\"]))\n",
    "print(\"Validation size:\", len(dataset[\"validation\"]))\n",
    "print(\"Test size:\", len(dataset[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de3a0610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  __index_level_0__\n",
      "0  Anarchy and lawlessness reign supreme in the p...      1              18135\n",
      "1  Before I begin, a \"little\" correction: IMDb st...      0              28917\n",
      "2  You know Jason, you know Freddy, and you know ...      0              10723\n",
      "3  Creative use of modern and mystical elements: ...      1              15970\n",
      "4  In the trivia section for Pet Sematary, it men...      1              23713\n",
      "5  Despite a totally misleading advertising campa...      0              33491\n",
      "6  Well, were to start? This is by far one of the...      0              12150\n",
      "7  What's written on the poster is: \"At birth he ...      0               8495\n",
      "8  Many of the earlier comments are right on the ...      1              40256\n",
      "9  i love this show. i hate when it goes to seaso...      1              38548\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dataset[\"train\"][:10])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42c88d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35238a36f85c4bc6aacf12d7b1cf654d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/35 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebba816c61314514bb58930e4ce582eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc4c8031a514ba4a19b63b6a5e40a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6669770"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].to_csv(\"imdb_train.csv\")\n",
    "dataset['validation'].to_csv(\"imdb_validation.csv\")\n",
    "dataset['test'].to_csv(\"imdb_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ea0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ∩ Validation: 0 overlapping samples\n",
      "Train ∩ Test:       0 overlapping samples\n",
      "Validation ∩ Test:  0 overlapping samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_val_overlap': set(),\n",
       " 'train_test_overlap': set(),\n",
       " 'val_test_overlap': set()}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# check duplicate text\n",
    "def check_data_leakage(train_path, val_path, test_path, text_column=\"text\"):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_val = pd.read_csv(val_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "\n",
    "    train_texts = set(df_train[text_column].dropna().unique())\n",
    "    val_texts = set(df_val[text_column].dropna().unique())\n",
    "    test_texts = set(df_test[text_column].dropna().unique())\n",
    "\n",
    "    # union check\n",
    "    train_val_overlap = train_texts & val_texts\n",
    "    train_test_overlap = train_texts & test_texts\n",
    "    val_test_overlap = val_texts & test_texts\n",
    "\n",
    "    # result\n",
    "    print(f\"Train ∩ Validation: {len(train_val_overlap)} overlapping samples\")\n",
    "    print(f\"Train ∩ Test:       {len(train_test_overlap)} overlapping samples\")\n",
    "    print(f\"Validation ∩ Test:  {len(val_test_overlap)} overlapping samples\")\n",
    "\n",
    "    if train_test_overlap:\n",
    "        print(\"\\n🚨 示例重复文本（Train ∩ Test）:\")\n",
    "        for i, text in enumerate(list(train_test_overlap)[:5]):\n",
    "            print(f\"- {text[:100]}...\")  # 只显示前 80 字符\n",
    "\n",
    "    return {\n",
    "        \"train_val_overlap\": train_val_overlap,\n",
    "        \"train_test_overlap\": train_test_overlap,\n",
    "        \"val_test_overlap\": val_test_overlap\n",
    "    }\n",
    "\n",
    "check_data_leakage(\n",
    "    train_path=\"imdb_train.csv\",\n",
    "    val_path=\"imdb_validation.csv\",\n",
    "    test_path=\"imdb_test.csv\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
